{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1dypu6r9KIDzA1p9B0h3FP55KMN2ZpP07","authorship_tag":"ABX9TyPTg0f/YFrTdn9sVCJXlyEc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"B-fqwTGkT5Tf","executionInfo":{"status":"ok","timestamp":1699201525865,"user_tz":-330,"elapsed":3486,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"]},{"cell_type":"code","source":["train_dir = '/content/drive/MyDrive/dataset2/train'\n","test_dir = '/content/drive/MyDrive/dataset2/validation'\n","\n","img_size = (150, 150)\n","batch_size = 32\n","\n","# Create ImageDataGenerator for training data and augmentation\n","train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n","\n","# Create ImageDataGenerator for testing data (only rescaling)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Load and prepare training data\n","train_data = train_datagen.flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n","\n","# Load and prepare testing data\n","test_data = test_datagen.flow_from_directory(test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ij9CVt1TUPwy","executionInfo":{"status":"ok","timestamp":1699201543613,"user_tz":-330,"elapsed":4029,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}},"outputId":"86bfbfb6-7e7f-474d-f9fb-180ce1a362ef"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1031 images belonging to 2 classes.\n","Found 258 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(256, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(512, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Reduce the learning rate dynamically\n","reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"6kEuzbSBU9iD","executionInfo":{"status":"ok","timestamp":1699201548610,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["history = model.fit(train_data, steps_per_epoch=train_data.samples // batch_size, epochs=3, validation_data=test_data,validation_steps=test_data.samples//batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbzqVRMLWFr2","executionInfo":{"status":"ok","timestamp":1699201895690,"user_tz":-330,"elapsed":342991,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}},"outputId":"60cfda76-f30b-4d3d-8ebb-54208212409b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","32/32 [==============================] - 181s 6s/step - loss: 0.6380 - accuracy: 0.5926 - val_loss: 0.3118 - val_accuracy: 0.8633\n","Epoch 2/3\n","32/32 [==============================] - 66s 2s/step - loss: 0.1269 - accuracy: 0.9540 - val_loss: 0.0172 - val_accuracy: 0.9922\n","Epoch 3/3\n","32/32 [==============================] - 64s 2s/step - loss: 0.0540 - accuracy: 0.9824 - val_loss: 0.0254 - val_accuracy: 0.9961\n"]}]},{"cell_type":"code","source":["import pickle\n","\n","with open('training_history.pkl', 'wb') as file:\n","    pickle.dump(history.history, file)\n","\n","\n","\n","# model.evaluate(test_data)"],"metadata":{"id":"cwm-EuvtW34y","executionInfo":{"status":"ok","timestamp":1699201943309,"user_tz":-330,"elapsed":7,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**Changing the Directory to saved Model Directory**"],"metadata":{"id":"9akilcKp1UQk"}},{"cell_type":"code","source":["cd /content/drive/MyDrive/Mini Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_VbuRJGK1bdf","executionInfo":{"status":"ok","timestamp":1699199795524,"user_tz":-330,"elapsed":30,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}},"outputId":"4280095d-1687-4898-85fb-6fdbbeafc19c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Mini Project\n"]}]},{"cell_type":"markdown","source":["**Change Permission to run ngrok**"],"metadata":{"id":"U66UlcWu9dmr"}},{"cell_type":"code","source":["!chmod +x ngrok"],"metadata":{"id":"XafjFpSJ9h4U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Adding authtoken of ngrok**"],"metadata":{"id":"5VdKbQXH4-HD"}},{"cell_type":"code","source":["!./ngrok authtoken 2GRsSvZq1eX8gBkC8vSDTeb6fpa_2Zrn9KB4ZLeVWeCbZLHE1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kaJqq3TV5EQX","executionInfo":{"status":"ok","timestamp":1699199796322,"user_tz":-330,"elapsed":813,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}},"outputId":"707dd5cc-9805-4e71-e160-2a0b61ec6d1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"markdown","source":["**Start the ngrok server**"],"metadata":{"id":"fJvH-Iou8DIX"}},{"cell_type":"code","source":["import subprocess\n","import time\n","\n","# Start ngrok\n","ngrok_process = subprocess.Popen(['./ngrok', 'http', '5000'])\n","\n","import requests\n","\n","# Sleep for a few seconds to allow ngrok to start\n","time.sleep(5)\n","\n","# Get ngrok URL using ngrok API\n","ngrok_url = 'http://localhost:4040/api/tunnels'\n","response = requests.get(ngrok_url)\n","ngrok_data = response.json()\n","\n","# Extract the ngrok URL\n","ngrok_url = ngrok_data['tunnels'][0]['public_url']\n","print(\"Ngrok URL:\", ngrok_url)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBwaGO5b_BdH","executionInfo":{"status":"ok","timestamp":1699199800944,"user_tz":-330,"elapsed":4633,"user":{"displayName":"Rajneesh Kumar Arya","userId":"04780868015015162629"}},"outputId":"c704b3f6-21f7-40af-bd1b-5296709552e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ngrok URL: https://acdb-35-239-68-162.ngrok-free.app\n"]}]},{"cell_type":"markdown","source":["**Creating Flask Application**"],"metadata":{"id":"Mxl63eyV0xGz"}},{"cell_type":"code","source":["from flask import Flask, request, jsonify, render_template\n","from PIL import Image\n","import numpy as np\n","import io\n","import base64\n","from tensorflow.keras.models import load_model\n","from flask import Flask, request, render_template\n","from tensorflow.keras.models import load_model\n","from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n","import matplotlib.pyplot as plt\n","import io\n","import numpy as np\n","\n","app = Flask(__name__)\n","\n","# Load the model and compile it (Replace 'my_model.h5' with your model's path)\n","model = load_model('Fake_image_detection_model.h5')\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Training data (Replace with your data)\n","# X_train, y_train = ...\n","# history = model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n","\n","history = model.fit(train_data, steps_per_epoch=train_data.samples // batch_size, epochs=3, validation_data=test_data,validation_steps=test_data.samples//batch_size)\n","# Assuming 'history' contains training history (loss and accuracy)\n","\n","# Function to generate accuracy and loss graph\n","def generate_graph():\n","    epochs = range(len(history.history['accuracy']))\n","    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n","    ax[0].plot(epochs, history.history['accuracy'], label='Training Accuracy')\n","    ax[0].plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n","    ax[0].set_title('Training and Validation Accuracy')\n","    ax[0].legend()\n","    ax[1].plot(epochs, history.history['loss'], label='Training Loss')\n","    ax[1].plot(epochs, history.history['val_loss'], label='Validation Loss')\n","    ax[1].set_title('Training and Validation Loss')\n","    ax[1].legend()\n","\n","    # Save the plot to a BytesIO object\n","    img = io.BytesIO()\n","    plt.savefig(img, format='png')\n","    img.seek(0)\n","    plt.close()\n","\n","    return img\n","\n","@app.route('/', methods=['GET', 'POST'])\n","def predict():\n","    def predict():\n","    if request.method == 'POST':\n","        file = request.files['file']\n","        img = Image.open(file.stream)\n","        img = img.resize((150, 150))\n","        img = np.array(img) / 255.0\n","        img = np.reshape(img, (1, 150, 150, 3))\n","        prediction = loaded_model.predict(img)\n","        if prediction[0][0] > 0.5:\n","            result = \"Real Image\"\n","            confidence_percentage = f\"{prediction[0][0] * 100:.2f}%\"\n","        else:\n","            result = \"Fake Image\"\n","            confidence_percentage = f\"{100 - prediction[0][0] * 100:.2f}%\"\n","\n","        # Convert image to base64 to display in HTML\n","        img = Image.fromarray((img.reshape(150, 150, 3) * 255).astype(np.uint8))\n","        image = io.BytesIO()\n","        img.save(image, format='PNG')\n","        image.seek(0)\n","        encoded_img = base64.b64encode(image.getvalue()).decode('utf-8')\n","        return render_template('index.html', prediction=prediction, confidence=confidence_percentage, image=encoded_img)\n","\n","@app.route('/model_summary')\n","def model_summary():\n","    summary = []\n","    model.summary(print_fn=lambda x: summary.append(x))\n","    return render_template('model_summary.html', summary=summary)\n","\n","@app.route('/model_performance')\n","def model_performance():\n","    graph = generate_graph()\n","    return render_template('model_performance.html', graph=graph.read().encode('base64'))\n","\n","if __name__ == '__main__':\n","    app.run()\n"],"metadata":{"id":"454WYdiJ0vHv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"56035bbf-746f-468a-8e3a-80bac363248d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app '__main__'\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n"," * Running on http://127.0.0.1:5000\n","INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:06] \"GET / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:06] \"GET /static/style.css HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:06] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 191ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:17] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:18] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 71ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:30] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:31] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:41] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:42] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:51] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:57:52] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 41ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:05] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:06] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 45ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:30] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:31] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 42ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:43] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:44] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 40ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:53] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:58:54] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 71ms/step\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:59:03] \"POST / HTTP/1.1\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [05/Nov/2023 15:59:04] \"\u001b[36mGET /static/style.css HTTP/1.1\u001b[0m\" 304 -\n"]}]}]}